{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Paths\n",
    "    DATA_PATH = \"MFSD\"  # Change this to your dataset path\n",
    "    OUTPUT_PATH = \"results/unet\"\n",
    "    \n",
    "    # Dataset parameters\n",
    "    IMG_SIZE = 256\n",
    "    BATCH_SIZE = 8\n",
    "    \n",
    "    # Training parameters\n",
    "    EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4\n",
    "    EARLY_STOPPING_PATIENCE = 10\n",
    "    \n",
    "    # Model parameters\n",
    "    N_CLASSES = 1  # Binary segmentation\n",
    "    INIT_FEATURES = 32  # Number of features in the first layer\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_PATH, \"models\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_PATH, \"visualizations\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    # Dataset parameters\n",
    "    IMG_SIZE = 256\n",
    "    BATCH_SIZE = 8\n",
    "    \n",
    "    # Training parameters\n",
    "    EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4\n",
    "    EARLY_STOPPING_PATIENCE = 10\n",
    "    \n",
    "    # Model parameters\n",
    "    N_CLASSES = 1  # Binary segmentation\n",
    "    INIT_FEATURES = 32  # Number of features in the first layer\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_PATH, \"models\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_PATH, \"visualizations\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    \"\"\"Dataset for mask segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, images_path, masks_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            images_path: List of paths to images\n",
    "            masks_path: List of paths to corresponding masks\n",
    "            transform: Optional transform to be applied on samples\n",
    "        \"\"\"\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Read image and mask\n",
    "        image = cv2.imread(self.images_path[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(self.masks_path[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Normalize image\n",
    "        image = image / 255.0\n",
    "        mask = mask / 255.0\n",
    "        \n",
    "        # Resize\n",
    "        image = cv2.resize(image, (Config.IMG_SIZE, Config.IMG_SIZE))\n",
    "        mask = cv2.resize(mask, (Config.IMG_SIZE, Config.IMG_SIZE))\n",
    "        \n",
    "        # Convert to tensors\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            # Apply transforms if provided\n",
    "            sample = self.transform({\"image\": image, \"mask\": mask})\n",
    "            image, mask = sample[\"image\"], sample[\"mask\"]\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution block for U-Net.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net architecture for image segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=3, n_classes=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(n_channels, init_features)\n",
    "        self.enc2 = DoubleConv(init_features, init_features * 2)\n",
    "        self.enc3 = DoubleConv(init_features * 2, init_features * 4)\n",
    "        self.enc4 = DoubleConv(init_features * 4, init_features * 8)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(init_features * 8, init_features * 16)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(init_features * 16, init_features * 8, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(init_features * 16, init_features * 8)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(init_features * 8, init_features * 4, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(init_features * 8, init_features * 4)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(init_features * 4, init_features * 2, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(init_features * 4, init_features * 2)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(init_features * 2, init_features, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(init_features * 2, init_features)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out = nn.Conv2d(init_features, n_classes, kernel_size=1)\n",
    "        \n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        x = self.pool(enc1)\n",
    "        \n",
    "        enc2 = self.enc2(x)\n",
    "        x = self.pool(enc2)\n",
    "        \n",
    "        enc3 = self.enc3(x)\n",
    "        x = self.pool(enc3)\n",
    "        \n",
    "        enc4 = self.enc4(x)\n",
    "        x = self.pool(enc4)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.upconv4(x)\n",
    "        x = torch.cat([x, enc4], dim=1)\n",
    "        x = self.dec4(x)\n",
    "        \n",
    "        x = self.upconv3(x)\n",
    "        x = torch.cat([x, enc3], dim=1)\n",
    "        x = self.dec3(x)\n",
    "        \n",
    "        x = self.upconv2(x)\n",
    "        x = torch.cat([x, enc2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "        \n",
    "        x = self.upconv1(x)\n",
    "        x = torch.cat([x, enc1], dim=1)\n",
    "        x = self.dec1(x)\n",
    "        \n",
    "        # Output\n",
    "        x = self.out(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights for better convergence.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice loss for segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # Flatten\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # Calculate Dice coefficient\n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2.0 * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskSegmentation:\n",
    "    \"\"\"Class for mask segmentation using U-Net.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the segmentation model.\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration class with model parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.best_model_path = None\n",
    "        \n",
    "        # Setup data paths\n",
    "        self.images_path = os.path.join(config.DATA_PATH, \"images\")\n",
    "        self.masks_path = os.path.join(config.DATA_PATH, \"masks\")\n",
    "        \n",
    "        # Get list of image files that have masks\n",
    "        self.image_files = sorted(glob(os.path.join(self.images_path, \"with_mask\", \"*.jpg\")))\n",
    "        self.mask_files = [os.path.join(self.masks_path, os.path.basename(img)) for img in self.image_files]\n",
    "        \n",
    "        print(f\"Found {len(self.image_files)} images with masks.\")\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Prepare datasets and dataloaders.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of train, validation, and test dataloaders\n",
    "        \"\"\"\n",
    "        # Split data into train, validation, and test sets\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            self.image_files, self.mask_files, test_size=0.3, random_state=42)\n",
    "        \n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "        \n",
    "        print(f\"Train: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}\")\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = MaskDataset(X_train, y_train)\n",
    "        val_dataset = MaskDataset(X_val, y_val)\n",
    "        test_dataset = MaskDataset(X_test, y_test)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=self.config.BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "        \n",
    "        return train_loader, val_loader, test_loader\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build and initialize the U-Net model.\"\"\"\n",
    "        model = UNet(\n",
    "            n_channels=3,\n",
    "            n_classes=self.config.N_CLASSES,\n",
    "            init_features=self.config.INIT_FEATURES\n",
    "        ).to(device)\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def train(self, train_loader, val_loader):\n",
    "        \"\"\"\n",
    "        Train the U-Net model.\n",
    "        \n",
    "        Args:\n",
    "            train_loader: DataLoader for training data\n",
    "            val_loader: DataLoader for validation data\n",
    "            \n",
    "        Returns:\n",
    "            History of training metrics\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        criterion = DiceLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.config.LEARNING_RATE)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        \n",
    "        # Initialize variables for early stopping\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Initialize history\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_iou': [],\n",
    "            'val_dice': []\n",
    "        }\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{self.config.EPOCHS} (Train)\"):\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_iou = 0\n",
    "            val_dice = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{self.config.EPOCHS} (Val)\"):\n",
    "                    images = images.to(device)\n",
    "                    masks = masks.to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    # Calculate IoU and Dice scores\n",
    "                    preds = (outputs > 0.5).float()\n",
    "                    iou = self.calculate_iou(preds, masks)\n",
    "                    dice = 1 - loss.item()  # Since we're using Dice loss\n",
    "                    \n",
    "                    val_iou += iou\n",
    "                    val_dice += dice\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            val_iou /= len(val_loader)\n",
    "            val_dice /= len(val_loader)\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Print metrics\n",
    "            print(f\"Epoch {epoch+1}/{self.config.EPOCHS}, \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Val IoU: {val_iou:.4f}, \"\n",
    "                  f\"Val Dice: {val_dice:.4f}\")\n",
    "            \n",
    "            # Save metrics to history\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_iou'].append(val_iou)\n",
    "            history['val_dice'].append(val_dice)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                \n",
    "                # Save model\n",
    "                model_path = os.path.join(\n",
    "                    self.config.OUTPUT_PATH, \"models\", f\"unet_epoch_{epoch+1}_val_loss_{val_loss:.4f}.pt\")\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                self.best_model_path = model_path\n",
    "                \n",
    "                print(f\"Model saved to {model_path}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= self.config.EARLY_STOPPING_PATIENCE:\n",
    "                print(f\"Early stopping after {epoch+1} epochs\")\n",
    "                break\n",
    "        \n",
    "        # Save training history\n",
    "        history_df = pd.DataFrame(history)\n",
    "        history_df.to_csv(os.path.join(self.config.OUTPUT_PATH, \"training_history.csv\"), index=False)\n",
    "        \n",
    "        # Plot training history\n",
    "        self.plot_training_history(history)\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def calculate_iou(self, pred, target):\n",
    "        \"\"\"\n",
    "        Calculate IoU score.\n",
    "        \n",
    "        Args:\n",
    "            pred: Predicted mask\n",
    "            target: Ground truth mask\n",
    "            \n",
    "        Returns:\n",
    "            IoU score\n",
    "        \"\"\"\n",
    "        # Flatten tensors\n",
    "        pred = pred.view(-1).cpu().numpy()\n",
    "        target = target.view(-1).cpu().numpy()\n",
    "        \n",
    "        # Calculate IoU\n",
    "        intersection = np.logical_and(pred, target).sum()\n",
    "        union = np.logical_or(pred, target).sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            return 1.0\n",
    "        \n",
    "        return intersection / union\n",
    "    \n",
    "    def plot_training_history(self, history):\n",
    "        \"\"\"\n",
    "        Plot training history.\n",
    "        \n",
    "        Args:\n",
    "            history: Dictionary of training metrics\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Plot losses\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['train_loss'], label='Train Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot metrics\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['val_iou'], label='Validation IoU')\n",
    "        plt.plot(history['val_dice'], label='Validation Dice')\n",
    "        plt.title('Metrics')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.config.OUTPUT_PATH, \"training_history.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "    def load_best_model(self):\n",
    "        \"\"\"Load the best model from training.\"\"\"\n",
    "        if self.best_model_path is None:\n",
    "            print(\"No best model path found. Please train the model first.\")\n",
    "            return False\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(self.best_model_path))\n",
    "        self.model.eval()\n",
    "        return True\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data.\n",
    "        \n",
    "        Args:\n",
    "            test_loader: DataLoader for test data\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        model.eval()\n",
    "        \n",
    "        test_iou = []\n",
    "        test_dice = []\n",
    "        \n",
    "        # For visualization\n",
    "        vis_images = []\n",
    "        vis_gt_masks = []\n",
    "        vis_pred_masks = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                preds = (outputs > 0.5).float()\n",
    "                \n",
    "                # Calculate metrics\n",
    "                batch_iou = self.calculate_iou(preds, masks)\n",
    "                batch_dice = self.calculate_dice(preds, masks)\n",
    "                \n",
    "                test_iou.append(batch_iou)\n",
    "                test_dice.append(batch_dice)\n",
    "                \n",
    "                # Store some samples for visualization\n",
    "                if len(vis_images) < 5:  # Store only the first 5 samples\n",
    "                    for i in range(min(images.size(0), 5 - len(vis_images))):\n",
    "                        vis_images.append(images[i].cpu())\n",
    "                        vis_gt_masks.append(masks[i].cpu())\n",
    "                        vis_pred_masks.append(preds[i].cpu())\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_iou = sum(test_iou) / len(test_iou)\n",
    "        avg_dice = sum(test_dice) / len(test_dice)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Test IoU: {avg_iou:.4f}\")\n",
    "        print(f\"Test Dice: {avg_dice:.4f}\")\n",
    "        \n",
    "        # Visualize results\n",
    "        self.visualize_predictions(vis_images, vis_gt_masks, vis_pred_masks)\n",
    "        \n",
    "        return {\n",
    "            \"iou\": avg_iou,\n",
    "            \"dice\": avg_dice\n",
    "        }\n",
    "\n",
    "    def calculate_dice(self, pred, target):\n",
    "        \"\"\"\n",
    "        Calculate Dice coefficient.\n",
    "        \n",
    "        Args:\n",
    "            pred: Predicted mask\n",
    "            target: Ground truth mask\n",
    "            \n",
    "        Returns:\n",
    "            Dice coefficient\n",
    "        \"\"\"\n",
    "        # Flatten tensors\n",
    "        pred = pred.view(-1).cpu().numpy()\n",
    "        target = target.view(-1).cpu().numpy()\n",
    "        \n",
    "        # Calculate Dice\n",
    "        intersection = np.logical_and(pred, target).sum()\n",
    "        return (2.0 * intersection) / (pred.sum() + target.sum() + 1e-8)\n",
    "\n",
    "    def visualize_predictions(self, images, gt_masks, pred_masks):\n",
    "        \"\"\"\n",
    "        Visualize and save predictions.\n",
    "        \n",
    "        Args:\n",
    "            images: List of input images\n",
    "            gt_masks: List of ground truth masks\n",
    "            pred_masks: List of predicted masks\n",
    "        \"\"\"\n",
    "        n_samples = len(images)\n",
    "        fig, axes = plt.subplots(n_samples, 3, figsize=(15, 5 * n_samples))\n",
    "        \n",
    "        if n_samples == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # Original image\n",
    "            img = images[i].permute(1, 2, 0).numpy()\n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title(\"Original Image\")\n",
    "            axes[i, 0].axis(\"off\")\n",
    "            \n",
    "            # Ground truth mask\n",
    "            gt_mask = gt_masks[i].squeeze().numpy()\n",
    "            axes[i, 1].imshow(gt_mask, cmap=\"gray\")\n",
    "            axes[i, 1].set_title(\"Ground Truth Mask\")\n",
    "            axes[i, 1].axis(\"off\")\n",
    "            \n",
    "            # Predicted mask\n",
    "            pred_mask = pred_masks[i].squeeze().numpy()\n",
    "            axes[i, 2].imshow(pred_mask, cmap=\"gray\")\n",
    "            axes[i, 2].set_title(\"Predicted Mask\")\n",
    "            axes[i, 2].axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.config.OUTPUT_PATH, \"visualizations/predictions.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"\n",
    "        Predict mask for a single image.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to input image\n",
    "            \n",
    "        Returns:\n",
    "            Predicted mask as numpy array\n",
    "        \"\"\"\n",
    "        # Load and preprocess image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Normalize and resize\n",
    "        image = image / 255.0\n",
    "        image = cv2.resize(image, (Config.IMG_SIZE, Config.IMG_SIZE))\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        # Make prediction\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.model(image)\n",
    "            pred_mask = (output > 0.5).float()\n",
    "        \n",
    "        # Convert to numpy\n",
    "        pred_mask = pred_mask.squeeze().cpu().numpy()\n",
    "        \n",
    "        return pred_mask\n",
    "\n",
    "    def predict_and_visualize(self, image_path, output_path=None):\n",
    "        \"\"\"\n",
    "        Predict mask for a single image and visualize result.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to input image\n",
    "            output_path: Path to save visualization (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Predicted mask as numpy array\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get prediction\n",
    "        pred_mask = self.predict(image_path)\n",
    "        \n",
    "        # Visualize\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(cv2.resize(image, (Config.IMG_SIZE, Config.IMG_SIZE)))\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        # Predicted mask\n",
    "        axes[1].imshow(pred_mask, cmap=\"gray\")\n",
    "        axes[1].set_title(\"Predicted Mask\")\n",
    "        axes[1].axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_path:\n",
    "            plt.savefig(output_path)\n",
    "        else:\n",
    "            plt.savefig(os.path.join(self.config.OUTPUT_PATH, \"visualizations\", \n",
    "                                    f\"pred_{os.path.basename(image_path)}\"))\n",
    "        \n",
    "        plt.close()\n",
    "        \n",
    "        return pred_mask\n",
    "\n",
    "    def run_experiment(self):\n",
    "        \"\"\"Run the full experiment: prepare data, train, and evaluate.\"\"\"\n",
    "        print(\"Preparing data...\")\n",
    "        train_loader, val_loader, test_loader = self.prepare_data()\n",
    "        \n",
    "        print(\"Building model...\")\n",
    "        self.build_model()\n",
    "        \n",
    "        print(\"Training model...\")\n",
    "        history = self.train(train_loader, val_loader)\n",
    "        \n",
    "        print(\"Loading best model...\")\n",
    "        self.load_best_model()\n",
    "        \n",
    "        print(\"Evaluating model...\")\n",
    "        results = self.evaluate(test_loader)\n",
    "        \n",
    "        # Save results to file\n",
    "        with open(os.path.join(self.config.OUTPUT_PATH, \"results.txt\"), \"w\") as f:\n",
    "            f.write(f\"IoU Score: {results['iou']:.4f}\\n\")\n",
    "            f.write(f\"Dice Coefficient: {results['dice']:.4f}\\n\")\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Initialize config\n",
    "    config = Config()\n",
    "    \n",
    "    # Initialize segmentation model\n",
    "    segmentation = MaskSegmentation(config)\n",
    "    \n",
    "    # Run experiment\n",
    "    results = segmentation.run_experiment()\n",
    "    \n",
    "    print(\"Experiment completed!\")\n",
    "    print(f\"Results: IoU={results['iou']:.4f}, Dice={results['dice']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
