{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskSegmenter:\n",
    "    \"\"\"\n",
    "    Class for implementing traditional region-based segmentation techniques\n",
    "    for face mask segmentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, output_path=\"output/traditional\"):\n",
    "        \"\"\"\n",
    "        Initialize the segmenter with dataset paths.\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to the MFSD dataset\n",
    "            output_path: Path to save results\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.output_path = output_path\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_path, \"visualizations\"), exist_ok=True)\n",
    "        \n",
    "        # Paths to images and masks\n",
    "        self.images_path = os.path.join(data_path, \"images\")\n",
    "        self.masks_path = os.path.join(data_path, \"masks\")\n",
    "        \n",
    "        # Get list of image files that have masks\n",
    "        self.image_files = sorted(glob(os.path.join(self.images_path, \"with_mask\", \"*.jpg\")))\n",
    "        self.mask_files = [os.path.join(self.masks_path, os.path.basename(img)) for img in self.image_files]\n",
    "        \n",
    "        print(f\"Found {len(self.image_files)} images with masks.\")\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"\n",
    "        Preprocess the image for segmentation.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "        \n",
    "        Returns:\n",
    "            Preprocessed image\n",
    "        \"\"\"\n",
    "        # Convert to HSV color space\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(hsv, (5, 5), 0)\n",
    "        \n",
    "        return blurred\n",
    "    \n",
    "    def threshold_based_segmentation(self, image):\n",
    "        \"\"\"\n",
    "        Segment mask using thresholding in HSV color space.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "        \n",
    "        Returns:\n",
    "            Binary mask of the segmented region\n",
    "        \"\"\"\n",
    "        # Preprocess image\n",
    "        preprocessed = self.preprocess_image(image)\n",
    "        \n",
    "        # Define color range for common mask colors (blue, green, white)\n",
    "        # These ranges can be tuned based on the dataset\n",
    "        blue_lower = np.array([90, 50, 50])\n",
    "        blue_upper = np.array([130, 255, 255])\n",
    "        \n",
    "        green_lower = np.array([35, 50, 50])\n",
    "        green_upper = np.array([85, 255, 255])\n",
    "        \n",
    "        white_lower = np.array([0, 0, 180])\n",
    "        white_upper = np.array([180, 30, 255])\n",
    "        \n",
    "        # Create masks for each color\n",
    "        blue_mask = cv2.inRange(preprocessed, blue_lower, blue_upper)\n",
    "        green_mask = cv2.inRange(preprocessed, green_lower, green_upper)\n",
    "        white_mask = cv2.inRange(preprocessed, white_lower, white_upper)\n",
    "        \n",
    "        # Combine masks\n",
    "        combined_mask = blue_mask | green_mask | white_mask\n",
    "        \n",
    "        # Apply morphological operations to improve mask\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def edge_based_segmentation(self, image):\n",
    "        \"\"\"\n",
    "        Segment mask using edge detection.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "        \n",
    "        Returns:\n",
    "            Binary mask of the segmented region\n",
    "        \"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply Gaussian blur\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        # Detect edges using Canny edge detector\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "        \n",
    "        # Perform dilation to close gaps in edges\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        dilated = cv2.dilate(edges, kernel, iterations=2)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Create empty mask\n",
    "        mask = np.zeros_like(gray)\n",
    "        \n",
    "        # Draw filled contours on mask\n",
    "        # Filter contours by area to remove small noise\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > 500:  # Adjust threshold as needed\n",
    "                cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "        \n",
    "        # Apply morphological operations to improve mask\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def hybrid_segmentation(self, image):\n",
    "        \"\"\"\n",
    "        Combine thresholding and edge-based methods for better segmentation.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "        \n",
    "        Returns:\n",
    "            Binary mask of the segmented region\n",
    "        \"\"\"\n",
    "        # Get masks from both methods\n",
    "        threshold_mask = self.threshold_based_segmentation(image)\n",
    "        edge_mask = self.edge_based_segmentation(image)\n",
    "        \n",
    "        # Combine the masks\n",
    "        combined_mask = cv2.bitwise_or(threshold_mask, edge_mask)\n",
    "        \n",
    "        # Apply morphological operations to improve mask\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        final_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Find the face region and restrict the mask to it\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        \n",
    "        face_mask = np.zeros_like(gray)\n",
    "        \n",
    "        # If face detected, restrict mask to lower part of face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Focus on lower half of face (where mask would be)\n",
    "            lower_face_y = int(y + 0.4 * h)\n",
    "            lower_face_h = int(h * 0.6)\n",
    "            \n",
    "            face_mask[lower_face_y:y+h, x:x+w] = 255\n",
    "        \n",
    "        # If no face detected, use the original mask\n",
    "        if len(faces) == 0:\n",
    "            return final_mask\n",
    "        \n",
    "        # Combine with face region\n",
    "        result_mask = cv2.bitwise_and(final_mask, face_mask)\n",
    "        \n",
    "        return result_mask\n",
    "    \n",
    "    def evaluate_segmentation(self, pred_masks, gt_masks):\n",
    "        \"\"\"\n",
    "        Evaluate segmentation results using various metrics.\n",
    "        \n",
    "        Args:\n",
    "            pred_masks: List of predicted mask images\n",
    "            gt_masks: List of ground truth mask images\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        iou_scores = []\n",
    "        dice_scores = []\n",
    "        accuracy_scores = []\n",
    "        \n",
    "        for pred, gt in zip(pred_masks, gt_masks):\n",
    "            # Convert to binary masks\n",
    "            pred_binary = (pred > 0).astype(np.float32).flatten()\n",
    "            gt_binary = (gt > 0).astype(np.float32).flatten()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            iou = jaccard_score(gt_binary, pred_binary, average='binary', zero_division=1)\n",
    "            dice = f1_score(gt_binary, pred_binary, average='binary', zero_division=1)\n",
    "            acc = accuracy_score(gt_binary, pred_binary)\n",
    "            \n",
    "            iou_scores.append(iou)\n",
    "            dice_scores.append(dice)\n",
    "            accuracy_scores.append(acc)\n",
    "        \n",
    "        results = {\n",
    "            \"IoU\": np.mean(iou_scores),\n",
    "            \"Dice\": np.mean(dice_scores),\n",
    "            \"Accuracy\": np.mean(accuracy_scores)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_results(self, image, gt_mask, pred_mask, idx, save=True):\n",
    "        \"\"\"\n",
    "        Visualize segmentation results.\n",
    "        \n",
    "        Args:\n",
    "            image: Original image\n",
    "            gt_mask: Ground truth mask\n",
    "            pred_mask: Predicted mask\n",
    "            idx: Image index\n",
    "            save: Whether to save the visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(gt_mask, cmap='gray')\n",
    "        plt.title(\"Ground Truth Mask\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_mask, cmap='gray')\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save:\n",
    "            save_path = os.path.join(self.output_path, \"visualizations\", f\"result_{idx}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    def run_segmentation(self, num_samples=None, visualize=True):\n",
    "        \"\"\"\n",
    "        Run the segmentation pipeline on the dataset.\n",
    "        \n",
    "        Args:\n",
    "            num_samples: Number of samples to process (None for all)\n",
    "            visualize: Whether to visualize results\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of evaluation results\n",
    "        \"\"\"\n",
    "        # Use a subset of images if specified\n",
    "        if num_samples is not None:\n",
    "            image_files = self.image_files[:num_samples]\n",
    "            mask_files = self.mask_files[:num_samples]\n",
    "        else:\n",
    "            image_files = self.image_files\n",
    "            mask_files = self.mask_files\n",
    "        \n",
    "        # Lists to store results\n",
    "        pred_masks = []\n",
    "        gt_masks = []\n",
    "        \n",
    "        # Process each image\n",
    "        for i, (img_path, mask_path) in enumerate(tqdm(zip(image_files, mask_files), total=len(image_files))):\n",
    "            # Read image and ground truth mask\n",
    "            image = cv2.imread(img_path)\n",
    "            gt_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # Apply segmentation\n",
    "            pred_mask = self.hybrid_segmentation(image)\n",
    "            \n",
    "            # Store results\n",
    "            pred_masks.append(pred_mask)\n",
    "            gt_masks.append(gt_mask)\n",
    "            \n",
    "            # Visualize results\n",
    "            if visualize and i % 10 == 0:  # Visualize every 10th image\n",
    "                self.visualize_results(image, gt_mask, pred_mask, i)\n",
    "        \n",
    "        # Evaluate results\n",
    "        results = self.evaluate_segmentation(pred_masks, gt_masks)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nSegmentation Results:\")\n",
    "        print(f\"IoU: {results['IoU']:.4f}\")\n",
    "        print(f\"Dice Score: {results['Dice']:.4f}\")\n",
    "        print(f\"Accuracy: {results['Accuracy']:.4f}\")\n",
    "        \n",
    "        # Save results to file\n",
    "        with open(os.path.join(self.output_path, \"results.txt\"), \"w\") as f:\n",
    "            f.write(\"Traditional Segmentation Results:\\n\")\n",
    "            f.write(f\"IoU: {results['IoU']:.4f}\\n\")\n",
    "            f.write(f\"Dice Score: {results['Dice']:.4f}\\n\")\n",
    "            f.write(f\"Accuracy: {results['Accuracy']:.4f}\\n\")\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results  Traditional_Segmentation.ipynb  Traditional_Segmentation.py\n"
     ]
    }
   ],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images with masks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segmentation Results:\n",
      "IoU: nan\n",
      "Dice Score: nan\n",
      "Accuracy: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to the MFSD dataset\n",
    "    data_path = \"../data/MSFD/1/img\" \n",
    "    \n",
    "    # Create segmenter\n",
    "    segmenter = MaskSegmenter(data_path)\n",
    "    \n",
    "    # Run segmentation\n",
    "    results = segmenter.run_segmentation(num_samples=None)  # Set to None to process all images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
